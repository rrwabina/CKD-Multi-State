{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import datetime\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from openpyxl import load_workbook\n",
    "from collections import Counter\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.chdir('M:/Shared drives/CKD_Progression/')\n",
    "\n",
    "drive = 'M'\n",
    "main_path = drive + ':/Shared drives/CKD_Progression/data/CKD_COHORT_Jan2010_Mar2024_v3.csv'\n",
    "main_path = drive + ':/Shared drives/CKD-DW-Sam/CKD_COHORT_Jan2010_Mar2024_ver1/result/CKD_COHORT_Jan2010_Mar2024_v1.csv'\n",
    "main_path = drive + ':/Shared drives/CKD_Progression/data/CKD_cohort_raw_2023_70325.parquet.gzip'\n",
    "data_path = drive + ':/Shared drives/CKD_Progression/data/'\n",
    "docs_path = drive + ':/Shared drives/CKD_Progression/docs/'\n",
    "save_path = drive + ':/Shared drives/CKD_Progression/save/'\n",
    "covariates_path = docs_path + 'covariates.csv'\n",
    "removecols_path = docs_path + 'remove_columns.csv'\n",
    "\n",
    "def get_patients_new():\n",
    "    folder_path = docs_path + 'CKD_first_dates_70325_COHORT_2.csv'\n",
    "    df = pd.read_csv(folder_path, encoding = 'utf-8')\n",
    "    df = df.drop_duplicates()\n",
    "    patient_list_flag = df['ENC_HN'].unique().tolist()\n",
    "    return patient_list_flag\n",
    "\n",
    "def study_period(df, column, start_date, end_date):\n",
    "    df[column] = pd.to_datetime(df[column], errors = 'coerce')\n",
    "    mask = (df[column] >= start_date) & (df[column] <= end_date)\n",
    "    df = df.loc[mask]\n",
    "    return df\n",
    "\n",
    "def exclusion_icd():\n",
    "    ''' \n",
    "    Enlists all ICD codes for the relevant cardiac diseases\n",
    "    Goal: Remove patients with ICD before CDK3\n",
    "    '''\n",
    "    path = docs_path + 'diagnosis and procedure.xlsx'\n",
    "    sheet_names = ['CVD', 'IHD', 'TIA', 'Hemorrhagic stroke', 'Ischemic stroke', 'Cerebrovascular']\n",
    "    ICD_CODES_DICT = {}\n",
    "    for diag in sheet_names:\n",
    "        df_disease = pd.read_excel(path, sheet_name = diag)\n",
    "        ICD_CODES_DICT[diag] = df_disease['ICD code'].to_list()\n",
    "    return ICD_CODES_DICT\n",
    "\n",
    "def remove_nonexistent(reference, function = 'sum'):\n",
    "    originals = pd.read_excel(docs_path + 'ms_data_function_ver3.xlsx')\n",
    "    originals_list = originals[originals['function'] == function]['variable'].tolist()\n",
    "    reference_list = reference.columns\n",
    "    return [elem for elem in originals_list if elem in reference_list]\n",
    "\n",
    "def remove_outliers(df, docs_path = docs_path):\n",
    "    file_path = docs_path + 'possible_range.xlsx'\n",
    "    possible_range = pd.read_excel(file_path)\n",
    "    check_range_columns = possible_range['variable'].tolist()\n",
    "    upper_values = possible_range['max'].astype(float).tolist()\n",
    "    lower_values = possible_range['min'].astype(float).tolist()\n",
    "\n",
    "    for covariate, upper, lower in tqdm(zip(check_range_columns, upper_values, lower_values), \n",
    "                                        total = len(check_range_columns), desc = 'Removing outliers'):\n",
    "        if covariate in df.columns:\n",
    "            df[covariate] = pd.to_numeric(df[covariate], errors = 'coerce')\n",
    "            outlier_mask = (df[covariate] < lower) | (df[covariate] > upper)\n",
    "            df.loc[outlier_mask, covariate] = np.NaN\n",
    "    return df\n",
    "\n",
    "def carry_covariates():\n",
    "    carry_df = pd.read_excel(docs_path + 'ms_data_function_ver3.xlsx')\n",
    "    forward_list = carry_df[carry_df['carry'] == 'forward']['variable'].tolist()\n",
    "    forback_list = carry_df[carry_df['carry'] == 'forward_backward']['variable'].tolist()\n",
    "    lumping_list = carry_df[carry_df['carry'] == 'ignore']['variable'].tolist()\n",
    "    fllzero_list = carry_df[carry_df['carry'] == 'fill_zero']['variable'].tolist()\n",
    "\n",
    "    all_columns = da.columns.tolist()\n",
    "    forward_list = list(set(all_columns).difference(forward_list))\n",
    "    forback_list = list(set(all_columns).difference(forback_list))\n",
    "    lumping_list = list(set(all_columns).difference(lumping_list))\n",
    "    fllzero_list = list(set(all_columns).difference(fllzero_list))\n",
    "\n",
    "    return forward_list, forback_list, lumping_list, fllzero_list\n",
    "\n",
    "def carried_values(patient_data):\n",
    "    forward_list, forback_list, lumping_list, fllzero_list = carry_covariates()\n",
    "    patient_data[forward_list] = patient_data[forward_list].fillna(method = 'ffill')\n",
    "    patient_data[forback_list] = patient_data[forback_list].fillna(method = 'ffill')\n",
    "    patient_data[forback_list] = patient_data[forback_list].fillna(method = 'bfill')\n",
    "    return patient_data\n",
    "\n",
    "def determine_outcome(df):\n",
    "    def update_columns(df, col_name, condition):\n",
    "        df.loc[condition, col_name] = 1\n",
    "        df[col_name] = df.groupby(['ENC_HN'])[col_name].ffill().fillna(0)\n",
    "    condition_patterns = exclusion_icd()\n",
    "    for condition, patterns in condition_patterns.items():\n",
    "        pattern_regex = '|'.join(patterns)\n",
    "        update_columns(df, condition, df['diagnosis_all'].astype(str).str.contains(pattern_regex, na = False))\n",
    "    df['stroke'] = df[['TIA', 'Hemorrhagic stroke', 'Ischemic stroke']].max(axis = 1)\n",
    "    df = df.drop(['TIA', 'Hemorrhagic stroke', 'Ischemic stroke'], axis = 1)\n",
    "    return df\n",
    "\n",
    "patients = get_patients_new() \n",
    "assert pd.Series(patients).nunique() == 70325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = pd.read_csv(covariates_path)\n",
    "ignore_covariates = covariates[covariates['ignore']    == 'IGNORE']['variable'].to_list()\n",
    "finals_covariates = covariates[covariates['ignore']    != 'IGNORE']['variable'].to_list()\n",
    "cleann_covariates = covariates[covariates['clean' ]    == 'CLEAN' ]['variable'].to_list()\n",
    "explor_covariates = covariates[covariates['explore '] == 'EXPLORE']['variable'].to_list()\n",
    "\n",
    "finals_covariates.remove('delta')\n",
    "finals_covariates.remove('modulo')\n",
    "\n",
    "remove = pd.read_csv(removecols_path).iloc[:, 0]\n",
    "remove = remove.tolist()\n",
    "for rem in remove:\n",
    "    finals_covariates.remove(rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(main_path, encoding = 'utf-8')\n",
    "# data = data[data['ENC_HN'].isin(patients)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[finals_covariates]\n",
    "df = df[[col for col in df.columns if col not in ['ENC_HN']][:0] + ['ENC_HN'] +\\\n",
    "        [col for col in df.columns if col not in ['ENC_HN']][0:]]\n",
    "df = determine_outcome(df)\n",
    "df['visit_date'] = pd.to_datetime(df['visit_date'], errors = 'coerce')\n",
    "df = df.sort_values(['ENC_HN', 'visit_date'])\n",
    "df['delta']  = df.groupby('ENC_HN')['visit_date'].transform(lambda x: (x - x.iloc[0]).dt.days)\n",
    "df['modulo_030'] = np.floor_divide(df['delta'], 30)\n",
    "df['modulo_180'] = np.floor_divide(df['delta'], 180)\n",
    "df['modulo_365'] = np.floor_divide(df['delta'], 365.25)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing outliers: 100%|██████████| 29/29 [00:00<00:00, 50.70it/s]\n"
     ]
    }
   ],
   "source": [
    "df = remove_outliers(df)\n",
    "\n",
    "mask = (df['BMI'].isnull()) & (df['BW'].notna()) & (df['height'].notna())\n",
    "df.loc[mask, 'BMI'] = np.divide(df['BW'], np.divide(df['height'], 100) ** 2)\n",
    "mask = (df['BMI'].notna()) & (df['BW'].isnull()) & (df['height'].notna())\n",
    "df.loc[mask, 'BW'] = np.multiply(np.power(np.divide(df['height'], 100), 2), df['BMI'])\n",
    "mask = (df['BMI'].notna()) & (df['BW'].notna()) & (df['height'].isnull())\n",
    "df.loc[mask, 'height'] = np.sqrt(np.divide(df['BW'], df['BMI'])) * 100\n",
    "\n",
    "mask = (df['Lipid_HDL'].isnull()) & (df['Lipid_LDL'].notna()) & (df['Lipid_Cholesterol'].notna()) & (df['Lipid_Triglyceride'].notna())\n",
    "df.loc[mask, 'Lipid_HDL'] = df['Lipid_Cholesterol'] - df['Lipid_LDL'] - np.divide(df['Lipid_Triglyceride'], 5)\n",
    "mask = (df['Lipid_HDL'].notna()) & (df['Lipid_LDL'].isnull()) & (df['Lipid_Cholesterol'].notna()) & (df['Lipid_Triglyceride'].notna())\n",
    "df.loc[mask, 'Lipid_LDL'] = df['Lipid_Cholesterol'] - df['Lipid_HDL'] - np.divide(df['Lipid_Triglyceride'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_list = remove_nonexistent(df, 'sum')\n",
    "max_list = remove_nonexistent(df, 'max')\n",
    "min_list = remove_nonexistent(df, 'min')\n",
    "fst_list = remove_nonexistent(df, 'first')\n",
    "lst_list = remove_nonexistent(df, 'last')\n",
    "ave_list = remove_nonexistent(df, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[min_list] = df[min_list].apply(pd.to_numeric, errors = 'coerce')\n",
    "df[max_list] = df[max_list].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "ds = df.groupby(['ENC_HN', 'modulo_365'])\n",
    "da = df.groupby(['ENC_HN', 'modulo_365'])[ave_list].mean().reset_index()\n",
    "da[min_list] = ds[min_list].agg('min').  reset_index()[min_list]\n",
    "da[fst_list] = ds[fst_list].agg('first').reset_index()[fst_list]\n",
    "da[lst_list] = ds[lst_list].agg('last'). reset_index()[lst_list]\n",
    "da[max_list] = ds[max_list].agg('max').  reset_index()[max_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23693"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df = da[da['modulo_365'] < 1]\n",
    "baseline_df = baseline_df[(baseline_df['CKD_stage'] == 'stage_3a')] \n",
    "baseline_df = baseline_df[(baseline_df['stroke'] == 0) & (baseline_df['CVD'] == 0) & (baseline_df['Cerebrovascular'] == 0) & (baseline_df['IHD'] == 0)] \n",
    "\n",
    "# 32579 patients with CKD3A\n",
    "# 2614 patients with stroke \n",
    "# 4640 patients with IHD\n",
    "# 314  patients with cerebrovascular\n",
    "# 8465 patients with CVD\n",
    "# Total patients removed: 8886 \n",
    "\n",
    "cohort_patients = baseline_df['ENC_HN'].unique().tolist()\n",
    "len(cohort_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "qoc_cohort = da[da['ENC_HN'].isin(cohort_patients)]\n",
    "qoc_cohort = qoc_cohort.reset_index(drop = True)\n",
    "qoc_cohort = qoc_cohort[qoc_cohort['modulo_365'] < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = qoc_cohort.columns.tolist()\n",
    "all_missing = pd.DataFrame(qoc_cohort.isnull().sum()).reset_index()\n",
    "all_missing.columns = ['columns', 'missing']\n",
    "all_missing['miss_rate'] = all_missing['missing'] / qoc_cohort.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute = True\n",
    "if execute:\n",
    "    qoc_cohort .to_csv(save_path + 'qoc_cohort_ver001.csv',  index = False)\n",
    "    all_missing.to_csv(save_path + 'qoc_mis365_ver001.csv',  index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
