{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import datetime\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from openpyxl import load_workbook\n",
    "from collections import Counter\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.chdir('J:/Shared drives/CKD_Progression/')\n",
    "\n",
    "drive = 'J'\n",
    "main_path = drive + ':/Shared drives/CKD_Progression/data/CKD_COHORT_Jan2010_Mar2024_v3.csv'\n",
    "main_path = drive + ':/Shared drives/CKD-DW-Sam/CKD_COHORT_Jan2010_Mar2024_ver1/result/CKD_COHORT_Jan2010_Mar2024_v1.csv'\n",
    "main_path = drive + ':/Shared drives/CKD_Progression/data/CKD_cohort_raw_2023_70325.parquet.gzip'\n",
    "data_path = drive + ':/Shared drives/CKD_Progression/data/'\n",
    "docs_path = drive + ':/Shared drives/CKD_Progression/docs/'\n",
    "save_path = drive + ':/Shared drives/CKD_Progression/save/'\n",
    "covariates_path = docs_path + 'covariates.csv'\n",
    "removecols_path = docs_path + 'remove_columns.csv'\n",
    "\n",
    "def get_patients_new():\n",
    "    folder_path = docs_path + 'CKD_first_dates_70325_COHORT_2.csv'\n",
    "    df = pd.read_csv(folder_path, encoding = 'utf-8')\n",
    "    df = df.drop_duplicates()\n",
    "    patient_list_flag = df['ENC_HN'].unique().tolist()\n",
    "    return patient_list_flag\n",
    "\n",
    "def study_period(df, column, start_date, end_date):\n",
    "    df[column] = pd.to_datetime(df[column], errors = 'coerce')\n",
    "    mask = (df[column] >= start_date) & (df[column] <= end_date)\n",
    "    df = df.loc[mask]\n",
    "    return df\n",
    "\n",
    "def exclusion_icd():\n",
    "    ''' \n",
    "    Enlists all ICD codes for the relevant cardiac diseases\n",
    "    Goal: Remove patients with ICD before CDK3\n",
    "    '''\n",
    "    path = docs_path + 'diagnosis and procedure.xlsx'\n",
    "    sheet_names = ['CVD', 'IHD', 'TIA', 'Hemorrhagic stroke', 'Ischemic stroke', 'Cerebrovascular']\n",
    "    ICD_CODES_DICT = {}\n",
    "    for diag in sheet_names:\n",
    "        df_disease = pd.read_excel(path, sheet_name = diag)\n",
    "        ICD_CODES_DICT[diag] = df_disease['ICD code'].to_list()\n",
    "    return ICD_CODES_DICT\n",
    "\n",
    "def remove_nonexistent(reference, function = 'sum'):\n",
    "    originals = pd.read_excel(docs_path + 'ms_data_function_ver3.xlsx')\n",
    "    originals_list = originals[originals['function'] == function]['variable'].tolist()\n",
    "    reference_list = reference.columns\n",
    "    return [elem for elem in originals_list if elem in reference_list]\n",
    "\n",
    "def remove_outliers(df, docs_path = docs_path):\n",
    "    file_path = docs_path + 'possible_range.xlsx'\n",
    "    possible_range = pd.read_excel(file_path)\n",
    "    check_range_columns = possible_range['variable'].tolist()\n",
    "    upper_values = possible_range['max'].astype(float).tolist()\n",
    "    lower_values = possible_range['min'].astype(float).tolist()\n",
    "\n",
    "    for covariate, upper, lower in tqdm(zip(check_range_columns, upper_values, lower_values), \n",
    "                                        total = len(check_range_columns), desc = 'Removing outliers'):\n",
    "        if covariate in df.columns:\n",
    "            df[covariate] = pd.to_numeric(df[covariate], errors = 'coerce')\n",
    "            outlier_mask = (df[covariate] < lower) | (df[covariate] > upper)\n",
    "            df.loc[outlier_mask, covariate] = np.NaN\n",
    "    return df\n",
    "\n",
    "def carry_covariates():\n",
    "    carry_df = pd.read_excel(docs_path + 'ms_data_function_ver3.xlsx')\n",
    "    forward_list = carry_df[carry_df['carry'] == 'forward']['variable'].tolist()\n",
    "    forback_list = carry_df[carry_df['carry'] == 'forward_backward']['variable'].tolist()\n",
    "    lumping_list = carry_df[carry_df['carry'] == 'ignore']['variable'].tolist()\n",
    "    fllzero_list = carry_df[carry_df['carry'] == 'fill_zero']['variable'].tolist()\n",
    "\n",
    "    all_columns = da.columns.tolist()\n",
    "    forward_list = list(set(all_columns).difference(forward_list))\n",
    "    forback_list = list(set(all_columns).difference(forback_list))\n",
    "    lumping_list = list(set(all_columns).difference(lumping_list))\n",
    "    fllzero_list = list(set(all_columns).difference(fllzero_list))\n",
    "\n",
    "    return forward_list, forback_list, lumping_list, fllzero_list\n",
    "\n",
    "def carried_values(patient_data):\n",
    "    forward_list, forback_list, lumping_list, fllzero_list = carry_covariates()\n",
    "    patient_data[forward_list] = patient_data[forward_list].fillna(method = 'ffill')\n",
    "    patient_data[forback_list] = patient_data[forback_list].fillna(method = 'ffill')\n",
    "    patient_data[forback_list] = patient_data[forback_list].fillna(method = 'bfill')\n",
    "    return patient_data\n",
    "\n",
    "def determine_outcome(df):\n",
    "    def update_columns(df, col_name, condition):\n",
    "        df.loc[condition, col_name] = 1\n",
    "        df[col_name] = df.groupby(['ENC_HN'])[col_name].ffill().fillna(0)\n",
    "    condition_patterns = exclusion_icd()\n",
    "    for condition, patterns in condition_patterns.items():\n",
    "        pattern_regex = '|'.join(patterns)\n",
    "        update_columns(df, condition, df['icd'].astype(str).str.contains(pattern_regex, na = False))\n",
    "    df['stroke'] = df[['TIA', 'Hemorrhagic stroke', 'Ischemic stroke']].max(axis = 1)\n",
    "    df = df.drop(['TIA', 'Hemorrhagic stroke', 'Ischemic stroke'], axis = 1)\n",
    "    return df\n",
    "\n",
    "patients = get_patients_new() \n",
    "assert pd.Series(patients).nunique() == 70325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = pd.read_csv(covariates_path)\n",
    "ignore_covariates = covariates[covariates['ignore']    == 'IGNORE']['variable'].to_list()\n",
    "finals_covariates = covariates[covariates['ignore']    != 'IGNORE']['variable'].to_list()\n",
    "cleann_covariates = covariates[covariates['clean' ]    == 'CLEAN' ]['variable'].to_list()\n",
    "explor_covariates = covariates[covariates['explore '] == 'EXPLORE']['variable'].to_list()\n",
    "\n",
    "finals_covariates.remove('delta')\n",
    "finals_covariates.remove('modulo')\n",
    "\n",
    "remove = pd.read_csv(removecols_path).iloc[:, 0]\n",
    "remove = remove.tolist()\n",
    "for rem in remove:\n",
    "    finals_covariates.remove(rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_literal_eval(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "df = data[['ENC_HN', 'visit_date','UA_protein_dipstick']]\n",
    "df = df[df['UA_protein_dipstick'].apply(lambda x: len(x) > 0)].to_csv('J:/Shared drives/CKD_QOC/data/protein_dipstick.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df = determine_outcome(df)\n",
    "df['visit_date'] = pd.to_datetime(df['visit_date'], errors = 'coerce')\n",
    "df = df.sort_values(['ENC_HN', 'visit_date'])\n",
    "df['delta']  = df.groupby('ENC_HN')['visit_date'].transform(lambda x: (x - x.iloc[0]).dt.days)\n",
    "df['modulo_030'] = np.floor_divide(df['delta'], 30)\n",
    "df['modulo_180'] = np.floor_divide(df['delta'], 180)\n",
    "df['modulo_365'] = np.floor_divide(df['delta'], 365.25)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_list = remove_nonexistent(df, 'sum')\n",
    "max_list = remove_nonexistent(df, 'max')\n",
    "min_list = remove_nonexistent(df, 'min')\n",
    "fst_list = remove_nonexistent(df, 'first')\n",
    "lst_list = remove_nonexistent(df, 'last')\n",
    "ave_list = remove_nonexistent(df, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[min_list] = df[min_list].apply(pd.to_numeric, errors = 'coerce')\n",
    "df[max_list] = df[max_list].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "ds = df.groupby(['ENC_HN', 'modulo_365'])\n",
    "da = df.groupby(['ENC_HN', 'modulo_365'])[ave_list].mean().reset_index()\n",
    "da[min_list] = ds[min_list].agg('min').  reset_index()[min_list]\n",
    "da[fst_list] = ds[fst_list].agg('first').reset_index()[fst_list]\n",
    "da[lst_list] = ds[lst_list].agg('last'). reset_index()[lst_list]\n",
    "da[max_list] = ds[max_list].agg('max').  reset_index()[max_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_df = da[da['modulo_365'] <= 1]\n",
    "# baseline_df = baseline_df[(baseline_df['CKD_stage'] == 'stage_3a')] \n",
    "# baseline_df = baseline_df[(baseline_df['stroke'] == 0) & (baseline_df['CVD'] == 0) & (baseline_df['Cerebrovascular'] == 0) & (baseline_df['IHD'] == 0)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "da[['ENC_HN', 'visit_date', 'Chem_glucose']].to_csv(save_path + 'glucose.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
