{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import pyampute\n",
    "import pickle \n",
    "import time\n",
    "import ast \n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import mstats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy import stats\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import tree\n",
    "from pyampute.ampute import MultivariateAmputation\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lifelines import CoxPHFitter, WeibullFitter, WeibullAFTFitter\n",
    "from datetime import datetime, date, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tableone import TableOne \n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import mean_absolute_error, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from statsmodels.gam.tests.test_penalized import df_autos\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import norm\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from app_transition_dict import get_transition_dict, get_transition_code\n",
    "from app_init import get_multi_state_covariates, get_multi_state_cov_quartiles\n",
    "from app_init import replace_covariate_labels, replace_pvalue, get_variables_cox\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "drive = 'G'\n",
    "main_path = drive + ':/Shared drives/CKD_Progression/data/CKD_COHORT_Jan2010_Mar2024_v3.csv'\n",
    "data_path = drive + ':/Shared drives/CKD_Progression/data/'\n",
    "docs_path = drive + ':/Shared drives/CKD_Progression/docs/'\n",
    "save_path = drive + ':/Shared drives/CKD_Progression/save/'\n",
    "resu_path = drive + ':/Shared drives/CKD_Progression/result/'\n",
    "covariates_path = docs_path + 'covariates.csv'\n",
    "removecols_path = docs_path + 'remove_columns.csv'\n",
    "\n",
    "def generate_df_continuous(df, variables, q = 3):\n",
    "    bins_dict = {} \n",
    "    for variable, prefix, column_name in variables:\n",
    "        df[column_name], bins = pd.qcut(\n",
    "            df[variable],\n",
    "            q = q,\n",
    "            labels = False,\n",
    "            duplicates = 'drop',\n",
    "            retbins = True)\n",
    "        bins_dict[variable] = bins\n",
    "        dummies = pd.get_dummies(df[column_name], prefix = prefix)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "    return df, bins_dict\n",
    "\n",
    "def generate_df_continuous_predefined(df, variables, get_columns = False):\n",
    "    for variable, prefix, column_name, bins, labels in variables:\n",
    "        df[column_name] = pd.cut(df[variable], bins = bins, labels = labels, right = False)\n",
    "\n",
    "        if get_columns:\n",
    "            dummies = pd.get_dummies(df[column_name], prefix = prefix)\n",
    "            df = pd.concat([df, dummies], axis = 1)\n",
    "    return df\n",
    "\n",
    "def get_first_dates():\n",
    "    heart_failure = pd.read_excel(docs_path + 'HF_FIRSTDATE_2010_2023.xlsx') ['ENC_HN'].unique().tolist()\n",
    "    hypertension  = pd.read_excel(docs_path + 'HTN_FIRSTDATE_2010_2023.xlsx')['ENC_HN'].unique().tolist()\n",
    "    diabetes = pd.read_csv(docs_path + 'DM_FIRSTDATE_2010_2023.csv')['ENC_HN'].unique().tolist()\n",
    "    atrialfb = pd.read_csv(docs_path + 'AF_FIRSTDATE_2010_2023.csv')['ENC_HN'].unique().tolist()\n",
    "    return heart_failure, hypertension, diabetes, atrialfb\n",
    "\n",
    "def merge_comorbidity(df, comorbidity, disease_code):\n",
    "    disease_column = disease_code.upper()\n",
    "    df[disease_column] = df['ENC_HN'].isin(comorbidity).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(version = '13', get_columns = False):\n",
    "    covariates, variables = get_multi_state_cov_quartiles(), get_variables_cox()\n",
    "    order_covariates = pd.read_csv(docs_path + 'cox_covariates.csv')\n",
    "    model_vars = ['ENC_HN', 'transition', 'fr', 'to', 'status', 'tstart', 'tstops', 'time']\n",
    "    heart_failure, hypertension, diabetes, atrialfb = get_first_dates()\n",
    "    \n",
    "    long_df = pd.read_csv(save_path + 'multi_state_long_ver0' + f'{version}.csv')\n",
    "    long_df['gender']  = long_df['gender'].replace('M', 1).replace('F', 0)\n",
    "    long_df['pathway'] = long_df['fr'] + '_to_' + long_df['to']\n",
    "    long_df = generate_df_continuous_predefined(long_df, variables, get_columns = get_columns)\n",
    "    long_df['statin']  = long_df[['statinhydro', 'statinlipo']].max(axis = 1)\n",
    "    long_df['raas']    = long_df[['arb', 'acei']].max(axis = 1)\n",
    "    long_df = long_df.drop(columns = ['statinhydro', 'statinlipo'])\n",
    "    long_df = merge_comorbidity(long_df, heart_failure, 'hf')\n",
    "    long_df = merge_comorbidity(long_df, diabetes,      'dm')\n",
    "    long_df = merge_comorbidity(long_df, atrialfb,      'af')\n",
    "    return covariates, order_covariates, long_df\n",
    "\n",
    "\n",
    "covariates, order_covariates, long_df = load_dataset(version = '13', get_columns = False)\n",
    "covariates.remove('Gout')\n",
    "covariates.remove('PHOS_BINDER')\n",
    "covariates.remove('ANTI_PL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coxph(long_df, covariate, pathway):\n",
    "    transition_data = long_df[long_df['pathway'] == pathway].copy()\n",
    "    cph = CoxPHFitter()\n",
    "    formula = f'C({covariate})'\n",
    "    cph_model = cph.fit(\n",
    "        transition_data,\n",
    "        duration_col = 'tstops',\n",
    "        event_col    = 'status',\n",
    "        formula = formula,\n",
    "        step_size = 0.1, \n",
    "        show_progress = False)\n",
    "    return cph_model\n",
    "\n",
    "def coxph_statistics(result):\n",
    "    roundup = 2\n",
    "    hazd = np.round(result.hazard_ratios_, roundup)[0]\n",
    "    ster = np.round(result.standard_errors_[0], roundup)\n",
    "    coef_low, coef_upp  = result.confidence_intervals_.reset_index().loc[0, '95% lower-bound'], \\\n",
    "                          result.confidence_intervals_.reset_index().loc[0, '95% upper-bound']\n",
    "    confidence_interval = f'({np.round(np.exp(coef_low), roundup)}, {np.round(np.exp(coef_upp), roundup)})'\n",
    "    pvalue = np.round(result._compute_p_values(), roundup)[0]\n",
    "    events_obs = result.event_observed.sum()\n",
    "    events_tot = result.event_observed.shape[0] \n",
    "    return hazd, confidence_interval, pvalue, ster, events_obs, events_tot\n",
    "\n",
    "def get_log_likelihood(cph_model):\n",
    "    deg = len(cph_model.params_)\n",
    "    LL0 = cph_model._ll_null_\n",
    "    LL1 = cph_model.log_likelihood_\n",
    "    LLR = -2 * (LL0 - LL1)\n",
    "    p_value = chi2.sf(LLR, len(cph_model.params_))\n",
    "    return deg, LL0, LL1, LLR, p_value\n",
    "\n",
    "def cox_table(cph_model, variable):\n",
    "    categorical = ['bin_bmi', 'bin_glu', 'bin_hba']\n",
    "    test_statistics = cph_model.log_likelihood_ratio_test().test_statistic\n",
    "    univariate_covariate = cph_model.summary.reset_index()\n",
    "    univariate_covariate['95CI HR'] = '(' + np.round(univariate_covariate['exp(coef) lower 95%'], 2).astype(str) + ', ' +\\\n",
    "                                            np.round(univariate_covariate['exp(coef) upper 95%'], 2).astype(str) + ')'\n",
    "    univariate_covariate = univariate_covariate.drop(columns = ['se(coef)', 'z',\n",
    "                                                                'coef lower 95%', \n",
    "                                                                'coef upper 95%', \n",
    "                                                                'exp(coef) lower 95%', \n",
    "                                                                'exp(coef) upper 95%',])\n",
    "    univariate_covariate = univariate_covariate.rename(columns = {'exp(coef)': 'HR', 'p': 'pvalue'})\n",
    "    univariate_covariate = univariate_covariate[['covariate', 'coef', 'HR', '95CI HR', 'pvalue']]\n",
    "    univariate_covariate['LLT'] = test_statistics\n",
    "    univariate_covariate['deg'] = len(cph_model.params_)\n",
    "    univariate_covariate = pd.concat([pd.DataFrame({'covariate': [variable], 'coef': [0], 'HR': [1], '95CI HR': np.NaN, 'pvalue': np.NaN}), \n",
    "                                    univariate_covariate], \n",
    "                                    ignore_index = True)\n",
    "    if variable in categorical:\n",
    "        deg, LL0, LL1, LLR, p_value = get_log_likelihood(cph_model)\n",
    "        univariate_covariate.loc[variable, 'LLT'] = LLR\n",
    "        univariate_covariate.loc[variable, 'deg'] = deg\n",
    "        univariate_covariate.loc[variable, 'pvalue'] = p_value\n",
    "    return univariate_covariate\n",
    "\n",
    "\n",
    "def univariate_coxph(df, pathway, save = False):\n",
    "    univariate_list = []\n",
    "    categorical = ['bin_bmi', 'bin_glu', 'bin_hba']\n",
    "    for covariate in tqdm(covariates):\n",
    "        cph_model = generate_coxph(df, covariate, pathway)\n",
    "        univariate_covariate = cox_table(cph_model, covariate)\n",
    "        univariate_covariate['percentage'] = df[df[covariate] == 1]['ENC_HN'].nunique()/df['ENC_HN'].nunique()\n",
    "        univariate_list.append(univariate_covariate)\n",
    "    univariate_df = pd.concat(univariate_list, axis = 0)\n",
    "    univariate_df = pd.merge(univariate_df, order_covariates, on = 'covariate', how = 'inner')\n",
    "    univariate_df = univariate_df[univariate_df['include'] == 1]\n",
    "    univariate_df = univariate_df.sort_values(['order'], ascending = True)\n",
    "    univariate_df['covariate'] = univariate_df['replace']\n",
    "    univariate_df['patient_observed'] = cph_model.event_observed.sum()\n",
    "    univariate_df['patient_risk'] = df['ENC_HN'].nunique()\n",
    "    univariate_df = univariate_df[['variable', 'covariate', 'patient_observed', 'patient_risk', 'LLT', 'deg', 'percentage', 'coef', 'HR', '95CI HR', 'pvalue']]\n",
    "    for var in ['coef', 'HR', 'pvalue', 'LLT', 'percentage']:\n",
    "        univariate_df[var] = np.round(univariate_df[var], 2)\n",
    "    univariate_df = replace_pvalue(univariate_df)\n",
    "    univariate_df['included'] = np.NaN\n",
    "    univariate_df['pvalue'] = chi2.sf(univariate_df['LLT'], univariate_df['deg'])\n",
    "    return univariate_df, cph_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = long_df['pathway'].unique().tolist()\n",
    "for path in ['CKD3A_to_CKD4', 'CKD3A_to_CKD5A', 'CKD3A_to_CKD5B', 'CKD3B_to_CKD5A', 'CKD3B_to_CKD5B', 'CKD4_to_CKD5B']:\n",
    "    pathways.remove(path)\n",
    "\n",
    "pathways = ['CKD5A_to_CKD5B']\n",
    "addition = ['CKD4_to_CKD5B'] \n",
    "\n",
    "\n",
    "execute = False \n",
    "if execute:\n",
    "    for idx, pathway in enumerate(pathways):\n",
    "        covariates, order_covariates, long_df = load_dataset(version = '13', get_columns = True)\n",
    "        covariates.remove('HF')\n",
    "        if idx >= 0:\n",
    "            long_df = long_df[long_df['HF'] == 0].reset_index(drop = True)\n",
    "        univariate, cph_model = univariate_coxph(long_df, pathway, save = False)\n",
    "        univariate['variable'] = univariate['variable'].replace('hdl_low ', 'hdl_low').replace('rua_normal ', 'rua_normal')\n",
    "        univariate.to_csv(resu_path + f'univariate/LR_test/{addition[idx]}.csv', index = False)\n",
    "\n",
    "    covariates, order_covariates, long_df = load_dataset(version = '13', get_columns = True)\n",
    "    for idx, pathway in enumerate(pathways):\n",
    "        df = long_df[long_df['pathway'] == pathway]\n",
    "        univariate = pd.read_csv(resu_path + f'univariate/LR_test/{addition[idx]}.csv')\n",
    "        percentage_columns = univariate['variable'].tolist()\n",
    "        univariate['percentage'] = univariate.apply(\n",
    "            lambda row: df[df[row['variable']] == 1]['ENC_HN'].nunique() / df['ENC_HN'].nunique() * 100, axis = 1)\n",
    "        univariate.to_csv(resu_path + f'univariate/LR_test/{addition[idx]}.csv', index = False)\n",
    "\n",
    "\n",
    "execute = False \n",
    "if execute:\n",
    "    path_list = [\n",
    "        os.path.join(os.path.join(resu_path, 'univariate/'), filename)\n",
    "        for filename in os.listdir(os.path.join(resu_path, 'univariate/LR_test'))\n",
    "        if filename.endswith(('.csv', '.xls', '.xlsx'))]\n",
    "\n",
    "    output_excel = resu_path + 'univariate/LR_test/univariate_results.xlsx'\n",
    "    with pd.ExcelWriter(output_excel, engine = 'openpyxl') as writer:\n",
    "        for file_path in path_list:\n",
    "            sheet_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            df = pd.read_csv(file_path)\n",
    "            df.to_excel(writer, sheet_name = sheet_name, index = False)\n",
    "\n",
    "execute = False \n",
    "if execute:\n",
    "    covariates, order_covariates, long_df = load_dataset(version = '13', get_columns = True)\n",
    "    for pathway in pathways:\n",
    "        df = long_df[long_df['pathway'] == pathway]\n",
    "        univariate = pd.read_csv(resu_path + f'univariate/LR_test/{pathway}.csv')\n",
    "        percentage_columns = univariate['variable'].tolist()\n",
    "        univariate['percentage'] = univariate.apply(\n",
    "            lambda row: df[df[row['variable']] == 1]['ENC_HN'].nunique() / df['ENC_HN'].nunique() * 100, axis = 1)\n",
    "        univariate.to_csv(resu_path + f'univariate/LR_test/{pathway}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coxph_multivariate(long_df, pathway, multivariate_covariates):\n",
    "    transition_data = long_df[long_df['pathway'] == pathway].copy()\n",
    "    cph = CoxPHFitter()\n",
    "    formula = multivariate_covariates\n",
    "    cph_model = cph.fit(\n",
    "        transition_data,\n",
    "        duration_col = 'tstops',\n",
    "        event_col    = 'status',\n",
    "        formula = formula,\n",
    "        step_size = 0.5)\n",
    "    return cph_model\n",
    "\n",
    "def validate(df):\n",
    "    df.loc[df['covariate'] == 'bmi_over', 'covariate'] = 'temp_placeholder'\n",
    "    df.loc[df['covariate'] == 'bmi_under', 'covariate'] = 'bmi_over'\n",
    "    df.loc[df['covariate'] == 'temp_placeholder', 'covariate'] = 'bmi_under'\n",
    "    return df\n",
    "\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['variable'] = X.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "    return vif_data\n",
    "\n",
    "def cox_multi_table(cph_model):\n",
    "    multivariate_covariate = cph_model.summary.reset_index()\n",
    "    multivariate_covariate['95CI HR'] = '(' + np.round(multivariate_covariate['exp(coef) lower 95%'], 2).astype(str) + ', ' +\\\n",
    "                                              np.round(multivariate_covariate['exp(coef) upper 95%'], 2).astype(str) + ')'\n",
    "    multivariate_covariate = multivariate_covariate.drop(columns = ['se(coef)', '-log2(p)', 'z',\n",
    "                                                                'coef lower 95%', \n",
    "                                                                'coef upper 95%', \n",
    "                                                                'exp(coef) lower 95%', \n",
    "                                                                'exp(coef) upper 95%',])\n",
    "    multivariate_covariate = multivariate_covariate.rename(columns = {'exp(coef)': 'HR', 'p': 'pvalue'})\n",
    "    multivariate_covariate = multivariate_covariate[['covariate', 'coef', 'HR', '95CI HR', 'pvalue']]\n",
    "    return multivariate_covariate\n",
    "\n",
    "covariates, order_covariates, long_df = load_dataset(version = '13', get_columns = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>lifelines.CoxPHFitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration col</th>\n",
       "      <td>'tstops'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event col</th>\n",
       "      <td>'status'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline estimation</th>\n",
       "      <td>breslow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of observations</th>\n",
       "      <td>23429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number of events observed</th>\n",
       "      <td>6268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial log-likelihood</th>\n",
       "      <td>-54243.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time fit was run</th>\n",
       "      <td>2025-01-04 06:40:35 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"min-width: 12px;\"></th>\n",
       "      <th style=\"min-width: 12px;\">coef</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef)</th>\n",
       "      <th style=\"min-width: 12px;\">se(coef)</th>\n",
       "      <th style=\"min-width: 12px;\">coef lower 95%</th>\n",
       "      <th style=\"min-width: 12px;\">coef upper 95%</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef) lower 95%</th>\n",
       "      <th style=\"min-width: 12px;\">exp(coef) upper 95%</th>\n",
       "      <th style=\"min-width: 12px;\">z</th>\n",
       "      <th style=\"min-width: 12px;\">p</th>\n",
       "      <th style=\"min-width: 12px;\">-log2(p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>0.30</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.46</td>\n",
       "      <td>7.41</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>42.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DM</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.33</td>\n",
       "      <td>7.59</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>44.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HT</th>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hba_high</th>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-14.95</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>165.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hba_prediabetes</th>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-12.82</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>122.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rua_hyper</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-3.80</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>12.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statin</th>\n",
       "      <td>0.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.24</td>\n",
       "      <td>5.84</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>27.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tri_high</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-3.52</td>\n",
       "      <td>&lt;0.005</td>\n",
       "      <td>11.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><br><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Concordance</th>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial AIC</th>\n",
       "      <td>108502.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log-likelihood ratio test</th>\n",
       "      <td>381.73 on 8 df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-log2(p) of ll-ratio test</th>\n",
       "      <td>255.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "\\begin{tabular}{lrrrrrrrrrr}\n",
       "\\toprule\n",
       "{} &  coef &  exp(coef) &  se(coef) &  coef lower 95\\% &  coef upper 95\\% &  exp(coef) lower 95\\% &  exp(coef) upper 95\\% &      z &    p &  -log2(p) \\\\\n",
       "covariate       &       &            &           &                 &                 &                      &                      &        &      &           \\\\\n",
       "\\midrule\n",
       "AF              &  0.30 &       1.35 &      0.04 &            0.22 &            0.38 &                 1.24 &                 1.46 &   7.41 & 0.00 &     42.80 \\\\\n",
       "DM              &  0.23 &       1.26 &      0.03 &            0.17 &            0.29 &                 1.18 &                 1.33 &   7.59 & 0.00 &     44.83 \\\\\n",
       "HT              & -0.06 &       0.95 &      0.03 &           -0.12 &            0.01 &                 0.89 &                 1.01 &  -1.68 & 0.09 &      3.44 \\\\\n",
       "hba\\_high        & -0.76 &       0.47 &      0.05 &           -0.86 &           -0.66 &                 0.42 &                 0.52 & -14.95 & 0.00 &    165.52 \\\\\n",
       "hba\\_prediabetes & -0.58 &       0.56 &      0.05 &           -0.67 &           -0.49 &                 0.51 &                 0.61 & -12.82 & 0.00 &    122.56 \\\\\n",
       "rua\\_hyper       & -0.10 &       0.90 &      0.03 &           -0.15 &           -0.05 &                 0.86 &                 0.95 &  -3.80 & 0.00 &     12.76 \\\\\n",
       "statin          &  0.16 &       1.17 &      0.03 &            0.11 &            0.21 &                 1.11 &                 1.24 &   5.84 & 0.00 &     27.51 \\\\\n",
       "tri\\_high        & -0.10 &       0.91 &      0.03 &           -0.15 &           -0.04 &                 0.86 &                 0.96 &  -3.52 & 0.00 &     11.18 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "<lifelines.CoxPHFitter: fitted with 23429 total observations, 17161 right-censored observations>\n",
       "             duration col = 'tstops'\n",
       "                event col = 'status'\n",
       "      baseline estimation = breslow\n",
       "   number of observations = 23429\n",
       "number of events observed = 6268\n",
       "   partial log-likelihood = -54243.39\n",
       "         time fit was run = 2025-01-04 06:40:35 UTC\n",
       "\n",
       "---\n",
       "                  coef  exp(coef)   se(coef)   coef lower 95%   coef upper 95%  exp(coef) lower 95%  exp(coef) upper 95%\n",
       "covariate                                                                                                               \n",
       "AF                0.30       1.35       0.04             0.22             0.38                 1.24                 1.46\n",
       "DM                0.23       1.26       0.03             0.17             0.29                 1.18                 1.33\n",
       "HT               -0.06       0.95       0.03            -0.12             0.01                 0.89                 1.01\n",
       "hba_high         -0.76       0.47       0.05            -0.86            -0.66                 0.42                 0.52\n",
       "hba_prediabetes  -0.58       0.56       0.05            -0.67            -0.49                 0.51                 0.61\n",
       "rua_hyper        -0.10       0.90       0.03            -0.15            -0.05                 0.86                 0.95\n",
       "statin            0.16       1.17       0.03             0.11             0.21                 1.11                 1.24\n",
       "tri_high         -0.10       0.91       0.03            -0.15            -0.04                 0.86                 0.96\n",
       "\n",
       "                     z      p   -log2(p)\n",
       "covariate                               \n",
       "AF                7.41 <0.005      42.80\n",
       "DM                7.59 <0.005      44.83\n",
       "HT               -1.68   0.09       3.44\n",
       "hba_high        -14.95 <0.005     165.52\n",
       "hba_prediabetes -12.82 <0.005     122.56\n",
       "rua_hyper        -3.80 <0.005      12.76\n",
       "statin            5.84 <0.005      27.51\n",
       "tri_high         -3.52 <0.005      11.18\n",
       "---\n",
       "Concordance = 0.57\n",
       "Partial AIC = 108502.78\n",
       "log-likelihood ratio test = 381.73 on 8 df\n",
       "-log2(p) of ll-ratio test = 255.19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pathway = 'CKD3A_to_CVD'\n",
    "univariate = pd.read_excel(resu_path + f'univariate/LR_test/{pathway}.xlsx')\n",
    "\n",
    "multivariate_covariates = univariate[univariate['included'] == 1]['variable'].tolist()\n",
    "continuous_covariates = ['bin_bmi']\n",
    "multivariate_covariates = ' + '.join(multivariate_covariates)\n",
    "\n",
    "multivariate_cox = generate_coxph_multivariate(long_df, pathway, multivariate_covariates)\n",
    "multivariate_transition = cox_multi_table(multivariate_cox)\n",
    "multivariate_transition['pvalue'] = np.round(multivariate_transition['pvalue'], 5)\n",
    "results = np.round(multivariate_cox.summary.reset_index().sort_values(['covariate'], ascending = True), 4)\n",
    "results = validate(results)\n",
    "multivariate_cox.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_list = [cov.strip() for cov in multivariate_covariates.split('+')]\n",
    "\n",
    "covariate_values = long_df[long_df['pathway'] == pathway][covariates_list].reset_index(drop = True)\n",
    "\n",
    "survival_func = multivariate_cox.predict_survival_function(covariate_values)\n",
    "survival_func.index = survival_func.index / 12\n",
    "transition_probabilities = []\n",
    "\n",
    "for year in range(1, 14):\n",
    "    t1 = year\n",
    "    t2 = year + 1\n",
    "    S_t1 = survival_func.loc[t1].values[0] if t1 in survival_func.index else survival_func.iloc[survival_func.index.get_loc(t1, method = 'nearest')].values[0]\n",
    "    S_t2 = survival_func.loc[t2].values[0] if t2 in survival_func.index else survival_func.iloc[survival_func.index.get_loc(t2, method = 'nearest')].values[0]\n",
    "    \n",
    "    if S_t1 is not None and S_t2 is not None:\n",
    "        transition_prob = 1 - S_t2\n",
    "        transition_probabilities.append({\n",
    "            'start': t1,\n",
    "            'end':   t2,\n",
    "            'transition_prob': round(transition_prob, 4)\n",
    "        })\n",
    "transition_prob_table = pd.DataFrame(transition_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:23<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "pathways = long_df['pathway'].unique().tolist()\n",
    "for path in ['CKD3A_to_CKD4', 'CKD3A_to_CKD5A', 'CKD3A_to_CKD5B', 'CKD3B_to_CKD5A', 'CKD3B_to_CKD5B', 'CKD4_to_CKD5B']:\n",
    "    pathways.remove(path)\n",
    "\n",
    "for pathway in tqdm(pathways):\n",
    "    univariate = pd.read_excel(resu_path + 'univariate/univariate_results.xlsx', sheet_name = pathway)\n",
    "    univariate_transition = pd.read_csv(resu_path + f'univariate/{pathway}.csv')\n",
    "\n",
    "    multivariate_covariates = univariate[univariate['included'] == 1]['variable'].tolist()\n",
    "    multivariate_covariates = ' + '.join(multivariate_covariates)\n",
    "\n",
    "    multivariate_cox = generate_coxph_multivariate(long_df, pathway, multivariate_covariates)\n",
    "    multivariate_transition = cox_multi_table(multivariate_cox)\n",
    "    for var in ['coef', 'HR', 'pvalue']:\n",
    "            multivariate_transition[var] = np.round(multivariate_transition[var], 2)\n",
    "    multivariate_transition = replace_pvalue(multivariate_transition)\n",
    "    multivariate_transition = multivariate_transition.rename(columns = {\n",
    "        'covariate': 'variable',\n",
    "        'coef':    'adj_coef',\n",
    "        'HR':      'adj_HR',\n",
    "        '95CI HR': 'adj_95CI_HR',\n",
    "        'pvalue':  'adj_pvalue'})\n",
    "    overall = pd.merge(univariate_transition, multivariate_transition, \n",
    "                    on = ['variable'], how = 'left')\n",
    "    overall.to_csv(resu_path + f'multivariate/{pathway}.csv', index = False)\n",
    "\n",
    "path_list = [\n",
    "    os.path.join(os.path.join(resu_path, 'multivariate/'), filename)\n",
    "    for filename in os.listdir(os.path.join(resu_path, 'multivariate/'))\n",
    "    if filename.endswith(('.csv', '.xls', '.xlsx'))]\n",
    "\n",
    "output_excel = resu_path + 'multivariate/multivariate_results.xlsx'\n",
    "with pd.ExcelWriter(output_excel, engine = 'openpyxl') as writer:\n",
    "    for file_path in path_list:\n",
    "        sheet_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.to_excel(writer, sheet_name = sheet_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "def calculate_c_index_and_brier_score(model, df, time_col, event_col, time_points):\n",
    "    predicted_survival = model.predict_survival_function(df, times=time_points)\n",
    "    c_index = concordance_index(df[time_col], -model.predict_partial_hazard(df), df[event_col])\n",
    "\n",
    "    integrated_brier_score = 0\n",
    "    valid_time_points = 0\n",
    "\n",
    "    for t in time_points:\n",
    "        predicted_probs = predicted_survival.loc[t]\n",
    "        actual_times = df[time_col]\n",
    "        actual_events = df[event_col]\n",
    "        sample_weights = (actual_times <= t)\n",
    "\n",
    "        if sample_weights.sum() > 0:\n",
    "            brier_at_t = brier_score_loss(\n",
    "                y_true=actual_events,\n",
    "                y_prob=predicted_probs,\n",
    "                sample_weight=sample_weights\n",
    "            )\n",
    "            integrated_brier_score += brier_at_t\n",
    "            valid_time_points += 1\n",
    "\n",
    "    if valid_time_points > 0:\n",
    "        integrated_brier_score /= valid_time_points\n",
    "    else:\n",
    "        integrated_brier_score = float('nan')  \n",
    "\n",
    "    return c_index, integrated_brier_score/30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.util import Surv\n",
    "transition_df = long_df[long_df['pathway'] == pathway]\n",
    "independent_df = transition_df.drop(columns = ['status'])\n",
    "independent_df = transition_df[multivariate_covariates]\n",
    "\n",
    "groundtruth_df = transition_df[['status', 'time']]\n",
    "groundtruth_df['status'] = groundtruth_df['status'].astype(bool)\n",
    "groundtruth_df['time'] = pd.to_numeric(groundtruth_df['time'])\n",
    "\n",
    "censored_weight = len(groundtruth_df) / groundtruth_df['status'].value_counts()[0]\n",
    "event_weight    = len(groundtruth_df) / groundtruth_df['status'].value_counts()[1]\n",
    "\n",
    "groundtruth_df['sample_weight'] = groundtruth_df['status'].apply(lambda x: event_weight if x else censored_weight)\n",
    "\n",
    "X, y = independent_df, Surv.from_dataframe('status', 'time', groundtruth_df)\n",
    "X_train, X_test, y_train, y_test, sample_weight_train,   sample_weight_test  = train_test_split(X, y, groundtruth_df['sample_weight'].to_numpy(), test_size = 0.20, random_state = 42)\n",
    "X_train, X_calib, y_train, y_calib, sample_weight_train, sample_weight_calib = train_test_split(\n",
    "    X_train, y_train, sample_weight_train, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.util import Surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.6\n",
    "calibration_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Assign each row to a dataset\n",
    "n = len(transition_df)\n",
    "train_end = int(n * train_ratio)\n",
    "calibration_end = train_end + int(n * calibration_ratio)\n",
    "\n",
    "# Shuffle the data to ensure randomness\n",
    "transition_df = transition_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Create a new column for the dataset assignment\n",
    "conditions = [\"train\"] * train_end + [\"calibration\"] * (calibration_end - train_end) + [\"test\"] * (n - calibration_end)\n",
    "transition_df[\"dataset\"] = conditions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:50<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "pathways = long_df['pathway'].unique().tolist()\n",
    "for path in ['CKD3A_to_CKD4', 'CKD3A_to_CKD5A', 'CKD3A_to_CKD5B', 'CKD3B_to_CKD5A', 'CKD3B_to_CKD5B', 'CKD4_to_CKD5B']:\n",
    "    pathways.remove(path)\n",
    "CINDEX, IBS = [], []\n",
    "for pathway in tqdm(pathways):\n",
    "    univariate = pd.read_excel(resu_path + f'univariate/LR_test/{pathway}.xlsx')\n",
    "\n",
    "    multivariate_covariates = univariate[univariate['included'] == 1]['variable'].tolist()\n",
    "    continuous_covariates = ['bin_bmi']\n",
    "\n",
    "    transition_df = long_df[long_df['pathway'] == pathway]\n",
    "\n",
    "    train_ratio = 0.6\n",
    "    calibration_ratio = 0.2\n",
    "    test_ratio = 0.2\n",
    "    n = len(transition_df)\n",
    "    train_end = int(n * train_ratio)\n",
    "    calibration_end = train_end + int(n * calibration_ratio)\n",
    "    transition_df = transition_df.sample(frac = 1, random_state = 42).reset_index(drop = True)\n",
    "    conditions = ['train'] * train_end + ['calibration'] * (calibration_end - train_end) + ['test'] * (n - calibration_end)\n",
    "    transition_df['dataset'] = conditions\n",
    "\n",
    "    transition_df = transition_df[transition_df['dataset'] == 'test']\n",
    "    multivariate_covariates = ' + '.join(multivariate_covariates)\n",
    "    multivariate_cox = generate_coxph_multivariate(transition_df, pathway, multivariate_covariates)\n",
    "    multivariate_transition = cox_multi_table(multivariate_cox)\n",
    "    multivariate_transition['pvalue'] = np.round(multivariate_transition['pvalue'], 5)\n",
    "    results = np.round(multivariate_cox.summary.reset_index().sort_values(['covariate'], ascending = True), 4)\n",
    "    results = validate(results)\n",
    "    results[['covariate', 'exp(coef)', 'p']]\n",
    "\n",
    "    transition_data = transition_df[transition_df['pathway'] == pathway]\n",
    "    time_col  = 'tstops'  \n",
    "    event_col = 'status'  \n",
    "    time_points = np.linspace(1, 1000, 1000)\n",
    "    c_index, integrated_brier = calculate_c_index_and_brier_score(multivariate_cox, transition_data, time_col, event_col, time_points)\n",
    "    CINDEX.append(c_index)\n",
    "    IBS.append(integrated_brier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data = (pathways, CINDEX, IBS)).T\n",
    "results.columns = ['pathways', 'cindex', 'brier']\n",
    "results.to_excel(resu_path + 'multivariate/COXPH_RESULTS_12January2025.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 13.51it/s]\n"
     ]
    }
   ],
   "source": [
    "pathways = long_df['pathway'].unique().tolist()\n",
    "for path in ['CKD3A_to_CKD4', 'CKD3A_to_CKD5A', 'CKD3A_to_CKD5B', 'CKD3B_to_CKD5A', 'CKD3B_to_CKD5B', 'CKD4_to_CKD5B']:\n",
    "    pathways.remove(path)\n",
    "\n",
    "RISK, EVENTS, CENSOR, RATE, PERSON_YEARS, INCIDENCE = [], [], [], [], [], []\n",
    "for pathway in tqdm(pathways):\n",
    "    transition_df = long_df[long_df['pathway'] == pathway].reset_index(drop = True)\n",
    "    num_risk   = transition_df['ENC_HN'].nunique()\n",
    "    num_events = transition_df['status'].sum()\n",
    "    num_censor = num_risk - num_events\n",
    "    rate_censor = (num_censor / num_risk) * 100\n",
    "    person_years = transition_df[transition_df['status'] == 1]['tstops'].sum() \n",
    "    incidence_rate = (num_events / person_years) * 1000\n",
    "    RISK.append(num_risk)\n",
    "    EVENTS.append(num_events)\n",
    "    CENSOR.append(num_censor)\n",
    "    RATE.append(rate_censor)\n",
    "    PERSON_YEARS.append(person_years)\n",
    "    INCIDENCE.append(incidence_rate)\n",
    "\n",
    "results = pd.DataFrame(data = (pathways, RISK, EVENTS, CENSOR, RATE, PERSON_YEARS, INCIDENCE)).T\n",
    "results.columns = ['pathways', 'risk', 'events', 'num_censor', 'censor_rate', 'person_years', 'incidence']\n",
    "base_results = resu_path + 'baseline_models/'\n",
    "results.to_csv(base_results + 'combined_analysis.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined results saved to G:/Shared drives/CKD_Progression/result/baseline_models/combined_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_results = resu_path + 'baseline_models/'\n",
    "all_files = [os.path.join(base_results, f) for f in os.listdir(base_results) \n",
    "             if os.path.isfile(os.path.join(base_results, f))]\n",
    "\n",
    "transition_paths = pd.read_excel(base_results + 'CoxPH.xlsx')['name'].unique().tolist()\n",
    "assert len(transition_paths) == 25\n",
    "\n",
    "model_order = ['CoxPH', 'RSF', 'SVM', 'XGBoost', 'DeepSurv']\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for file_path in all_files:\n",
    "    model_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    if model_name not in model_order:\n",
    "        continue\n",
    "    if file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "    elif file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    else:\n",
    "        continue\n",
    "    for transition in transition_paths:\n",
    "        transition_df = df[df['name'] == transition]\n",
    "        if not transition_df.empty:\n",
    "            combined_data.append({\n",
    "                'transition': transition,\n",
    "                'model': model_name,\n",
    "                'fit_predict_time': transition_df['fit_predict_time'].values[0],\n",
    "                'cindex': transition_df['cindex'].values[0],\n",
    "                'r_cindex': transition_df['r_cindex'].values[0],\n",
    "                'brier': transition_df['brier'].values[0],\n",
    "                'r_brier': transition_df['r_brier'].values[0],\n",
    "                'ace': transition_df['ace'].values[0],\n",
    "            })\n",
    "\n",
    "final_df = pd.DataFrame(combined_data)\n",
    "final_df['model'] = pd.Categorical(final_df['model'], categories=model_order, ordered=True)\n",
    "final_df['fit_predict_time'] = np.round(final_df['fit_predict_time'], 2)\n",
    "final_df['cindex'] = np.round(final_df['cindex'] * 100, 2)\n",
    "final_df['r_cindex'] = np.round(final_df['r_cindex'] * 100, 2)\n",
    "final_df['brier'] = np.round(final_df['brier'], 4)\n",
    "final_df['r_brier'] = np.round(final_df['r_brier'], 4)\n",
    "final_df['ace'] = np.round(final_df['ace'], 4) \n",
    "final_df = final_df.sort_values(['transition', 'model'])\n",
    "\n",
    "\n",
    "output_path = base_results + 'combined_results.xlsx'\n",
    "final_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Combined results saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
